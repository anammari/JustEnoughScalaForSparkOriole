{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types will be printed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Either[org.apache.toree.magic.CellMagicOutput,org.apache.toree.magic.LineMagicOutput] = Right(())"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%showTypes on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Toree creates a SparkContext automatically "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.SparkContext = org.apache.spark.SparkContext@b10b77b"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version:      2.3.0\n",
      "Spark master:       local[*]\n",
      "Running 'locally'?: true\n"
     ]
    }
   ],
   "source": [
    "println(\"Spark version:      \" + sc.version)\n",
    "println(\"Spark master:       \" + sc.master)\n",
    "println(\"Running 'locally'?: \" + sc.isLocal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example methods in scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/*\n",
    " * \"info\" takes a single String argument, prints it on a line,\n",
    " * and returns it. \n",
    " */\n",
    "def info(message: String): String = {\n",
    "    println(message)\n",
    "\n",
    "    // The last expression in the block, message, is the return value. \n",
    "    // \"return\" keyword not required.\n",
    "    // Do no additional formatting for the return string.\n",
    "    message  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "/*\n",
    " * \"error\" takes a single String argument, prints a formatted error message,\n",
    " * and returns the message. \n",
    " */\n",
    "def error(message: String): String = {   \n",
    "\n",
    "    // Print the string passed to \"println\" and add a linefeed (\"ln\"):\n",
    "    // See the next cell for an explanation of how the string is constructed.\n",
    "    val fullMessage = s\"\"\"\n",
    "        |********************************************************************\n",
    "        |\n",
    "        |  ERROR: $message\n",
    "        |\n",
    "        |********************************************************************\n",
    "        |\"\"\".stripMargin\n",
    "    println(fullMessage)\n",
    "\n",
    "    fullMessage\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All is well.\n"
     ]
    }
   ],
   "source": [
    "val infoString = info(\"All is well.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "String = All is well."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infoString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************************************************\n",
      "\n",
      "  ERROR: Uh oh...\n",
      "\n",
      "********************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val errorString = error(\"Uh oh...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "String = \"\n",
       "line 1\n",
       "  line 2\n",
       " line 3\n",
       "\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s\"\"\"\n",
    "    |line 1\n",
    "    |  line 2\n",
    "    |  | line 3\n",
    "    |\"\"\".stripMargin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "String = \"\n",
       "line 1\n",
       "  line 2\n",
       "\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    |line 1\n",
    "    |  line 2\n",
    "    |\"\"\".stripMargin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Import File. Unlike Java, the semicolon ';' is not required.\n",
    "import java.io.File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val shakespeare = new File(\"JustEnoughScalaForSpark/data/shakespeare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JustEnoughScalaForSpark/data/shakespeare already exists\n",
      "success = true\n"
     ]
    }
   ],
   "source": [
    "val success = if (shakespeare.exists == false) {   // doesn't exist already?\n",
    "    error(s\"Data directory path doesn't exist! $shakespeare\")  // ignore returned string\n",
    "    false\n",
    "} else {\n",
    "    info(s\"$shakespeare already exists\")\n",
    "    true\n",
    "}\n",
    "println(\"success = \" + success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking that the plays are in JustEnoughScalaForSpark/data/shakespeare:\n",
      "Finished!\n",
      "All plays found!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Any = All plays found!"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pathSeparator = File.separator\n",
    "val targetDirName = shakespeare.toString\n",
    "val plays = Seq(\n",
    "    \"tamingoftheshrew\", \"comedyoferrors\", \"loveslabourslost\", \"midsummersnightsdream\",\n",
    "    \"merrywivesofwindsor\", \"muchadoaboutnothing\", \"asyoulikeit\", \"twelfthnight\")\n",
    "\n",
    "if (success) {\n",
    "    println(s\"Checking that the plays are in $shakespeare:\")\n",
    "    val failures = for {\n",
    "        play <- plays\n",
    "        playFileName = targetDirName + pathSeparator + play\n",
    "        playFile = new File(playFileName)\n",
    "        if (playFile.exists == false) \n",
    "    } yield {\n",
    "        s\"$playFileName:\\tNOT FOUND!\"\n",
    "    }\n",
    "\n",
    "    println(\"Finished!\")\n",
    "    if (failures.size == 0) {\n",
    "        info(\"All plays found!\")\n",
    "    } else {\n",
    "        println(\"The following expected plays were not found:\")\n",
    "        failures.foreach(play => error(play))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing Functions as Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass println as the function to use for each element:\n",
      "tamingoftheshrew\n",
      "comedyoferrors\n",
      "loveslabourslost\n",
      "midsummersnightsdream\n",
      "merrywivesofwindsor\n",
      "muchadoaboutnothing\n",
      "asyoulikeit\n",
      "twelfthnight\n"
     ]
    }
   ],
   "source": [
    "println(\"Pass println as the function to use for each element:\")\n",
    "plays.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using an anonymous function that calls println: `str => println(str)`\n",
      "(Note that the type of the argument `str` is inferred to be String.)\n",
      "tamingoftheshrew\n",
      "comedyoferrors\n",
      "loveslabourslost\n",
      "midsummersnightsdream\n",
      "merrywivesofwindsor\n",
      "muchadoaboutnothing\n",
      "asyoulikeit\n",
      "twelfthnight\n"
     ]
    }
   ],
   "source": [
    "println(\"\\nUsing an anonymous function that calls println: `str => println(str)`\")\n",
    "println(\"(Note that the type of the argument `str` is inferred to be String.)\")\n",
    "plays.foreach(str => println(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding the argument type explicitly. Note that the parentheses are required.\n",
      "tamingoftheshrew\n",
      "comedyoferrors\n",
      "loveslabourslost\n",
      "midsummersnightsdream\n",
      "merrywivesofwindsor\n",
      "muchadoaboutnothing\n",
      "asyoulikeit\n",
      "twelfthnight\n"
     ]
    }
   ],
   "source": [
    "println(\"\\nAdding the argument type explicitly. Note that the parentheses are required.\")\n",
    "plays.foreach((str: String) => println(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Why do we need to name this argument? Scala lets us use _ as a placeholder.\n",
      "tamingoftheshrew\n",
      "comedyoferrors\n",
      "loveslabourslost\n",
      "midsummersnightsdream\n",
      "merrywivesofwindsor\n",
      "muchadoaboutnothing\n",
      "asyoulikeit\n",
      "twelfthnight\n"
     ]
    }
   ],
   "source": [
    "println(\"\\nWhy do we need to name this argument? Scala lets us use _ as a placeholder.\")\n",
    "plays.foreach(println(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For longer functions, you can use {...} instead of (...).\n",
      "Why? Because it gives you the familiar multiline block syntax with {...}\n",
      "tamingoftheshrew\n",
      "comedyoferrors\n",
      "loveslabourslost\n",
      "midsummersnightsdream\n",
      "merrywivesofwindsor\n",
      "muchadoaboutnothing\n",
      "asyoulikeit\n",
      "twelfthnight\n"
     ]
    }
   ],
   "source": [
    "println(\"\\nFor longer functions, you can use {...} instead of (...).\")\n",
    "println(\"Why? Because it gives you the familiar multiline block syntax with {...}\")\n",
    "plays.foreach {\n",
    "  (str: String) => println(str)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an assume, use `reduceLeft` to sum some integers.\n"
     ]
    }
   ],
   "source": [
    "println(\"As an assume, use `reduceLeft` to sum some integers.\")\n",
    "val integers = 0 to 10   // Return a \"range\" from 0 to 10, inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int = 55"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Method 1: Use a function\n",
    "val f = (x:Int, y:Int) => x + y\n",
    "integers.reduceLeft(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The _ placeholder can be used *once* for each argument in the list.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Int = 55"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Method 2: \n",
    "println(\"\\nThe _ placeholder can be used *once* for each argument in the list.\")\n",
    "integers.reduceLeft(_+_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int = 55"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Method 2: anonymous function\n",
    "integers.reduceLeft((i,j) => i+j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our First Spark Program:\n",
    "\n",
    "outputs for each word a list of the documents that contain it, along with the corresponding counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "val iiFirstPass1 = sc.wholeTextFiles(shakespeare.toString).\n",
    "    flatMap { location_contents_tuple2 => \n",
    "        val words = location_contents_tuple2._2.split(\"\"\"\\W+\"\"\")\n",
    "        val fileName = location_contents_tuple2._1.split(pathSeparator).last\n",
    "        words.map(word => ((word, fileName), 1))\n",
    "    }.\n",
    "    reduceByKey((count1, count2) => count1 + count2).\n",
    "    map { word_file_count_tup3 => \n",
    "        (word_file_count_tup3._1._1, (word_file_count_tup3._1._2, word_file_count_tup3._2)) \n",
    "    }.\n",
    "    groupByKey.\n",
    "    sortByKey(ascending = true).\n",
    "    mapValues { iterable => \n",
    "        val vect = iterable.toVector.sortBy { file_count_tup2 => \n",
    "            (-file_count_tup2._2, file_count_tup2._1)\n",
    "        }\n",
    "        vect.mkString(\",\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(,(asyoulikeit,1),(comedyoferrors,1),(loveslabourslost,1),(merrywivesofwindsor,1),(midsummersnightsdream,1),(muchadoaboutnothing,1),(tamingoftheshrew,1),(twelfthnight,1))\n",
      "(A,(loveslabourslost,78),(tamingoftheshrew,59),(twelfthnight,47),(comedyoferrors,42),(midsummersnightsdream,39),(merrywivesofwindsor,38),(asyoulikeit,34),(muchadoaboutnothing,31))\n",
      "(ABOUT,(muchadoaboutnothing,18))\n",
      "(ACT,(merrywivesofwindsor,23),(asyoulikeit,22),(twelfthnight,18),(muchadoaboutnothing,17),(tamingoftheshrew,12),(comedyoferrors,11),(loveslabourslost,9),(midsummersnightsdream,9))\n",
      "(ADAM,(asyoulikeit,16))\n",
      "(ADO,(muchadoaboutnothing,18))\n",
      "(ADRIANA,(comedyoferrors,85))\n",
      "(ADRIANO,(loveslabourslost,111))\n",
      "(AEGEON,(comedyoferrors,20))\n",
      "(AEMELIA,(comedyoferrors,16))\n",
      "(AEMILIA,(comedyoferrors,3))\n",
      "(AEacides,(tamingoftheshrew,1))\n",
      "(AEgeon,(comedyoferrors,7))\n",
      "(AEgle,(midsummersnightsdream,1))\n",
      "(AEmilia,(comedyoferrors,4))\n",
      "(AEsculapius,(merrywivesofwindsor,1))\n",
      "(AGUECHEEK,(twelfthnight,2))\n",
      "(ALL,(midsummersnightsdream,2),(tamingoftheshrew,2))\n",
      "(AMIENS,(asyoulikeit,16))\n",
      "(ANDREW,(twelfthnight,104))\n",
      "(ANGELO,(comedyoferrors,36))\n",
      "(ANN,(merrywivesofwindsor,1))\n",
      "(ANNE,(merrywivesofwindsor,27))\n",
      "(ANTIPHOLUS,(comedyoferrors,195))\n",
      "(ANTONIO,(muchadoaboutnothing,32),(twelfthnight,32))\n",
      "(ARMADO,(loveslabourslost,111))\n",
      "(AS,(asyoulikeit,24))\n",
      "(AUDREY,(asyoulikeit,18))\n",
      "(Abate,(loveslabourslost,1),(midsummersnightsdream,1))\n",
      "(Abbess,(comedyoferrors,2))\n"
     ]
    }
   ],
   "source": [
    "iiFirstPass1.take(30).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.rdd.RDD[(String, String)] = JustEnoughScalaForSpark/data/shakespeare MapPartitionsRDD[85] at wholeTextFiles at <console>:22"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fileContents = sc.wholeTextFiles(shakespeare.toString)\n",
    "fileContents   // force the notebook to print the type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(String, Int, Double, (String, Long)) = (foo,101,3.14159,(bar,202))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\"foo\", 101, 3.14159, (\"bar\", 202L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Long = 8"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileContents.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.rdd.RDD[((String, String), Int)] = MapPartitionsRDD[12] at flatMap at <console>:26"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val wordFileNameOnes = fileContents.flatMap { location_contents_tuple2 => \n",
    "    // example input record: (file_path, \"all the words in the file\")\n",
    "    // mytuple._2 => give me the 2nd element\n",
    "    val words = location_contents_tuple2._2.split(\"\"\"\\W+\"\"\")              \n",
    "    // mytuple._1 => give me the 1st element\n",
    "    val fileName = location_contents_tuple2._1.split(pathSeparator).last  \n",
    "    // create a new tuple to return. Note how we structured it!\n",
    "    words.map(word => ((word, fileName), 1))\n",
    "}\n",
    "wordFileNameOnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.rdd.RDD[((String, String), Int)] = MapPartitionsRDD[12] at flatMap at <console>:26"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordFileNameOnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((,asyoulikeit),1)\n",
      "((AS,asyoulikeit),1)\n",
      "((YOU,asyoulikeit),1)\n",
      "((LIKE,asyoulikeit),1)\n",
      "((IT,asyoulikeit),1)\n",
      "((DRAMATIS,asyoulikeit),1)\n",
      "((PERSONAE,asyoulikeit),1)\n",
      "((DUKE,asyoulikeit),1)\n",
      "((SENIOR,asyoulikeit),1)\n",
      "((living,asyoulikeit),1)\n"
     ]
    }
   ],
   "source": [
    "wordFileNameOnes.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.rdd.RDD[((String, String), Int)] = ShuffledRDD[13] at reduceByKey at <console>:28"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val uniques = wordFileNameOnes.reduceByKey((count1, count2) => count1 + count2)\n",
    "uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Long = 27276"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((dexterity,merrywivesofwindsor),1)\n",
      "((crest,asyoulikeit),1)\n",
      "((whole,comedyoferrors),2)\n",
      "((lamb,muchadoaboutnothing),2)\n",
      "((force,muchadoaboutnothing),2)\n",
      "((letter,merrywivesofwindsor),19)\n",
      "((blunt,tamingoftheshrew),3)\n",
      "((bestow,asyoulikeit),1)\n",
      "((rear,midsummersnightsdream),1)\n",
      "((crossing,tamingoftheshrew),1)\n",
      "((wronged,merrywivesofwindsor),4)\n",
      "((S,tamingoftheshrew),10)\n",
      "((HIPPOLYTA,midsummersnightsdream),19)\n",
      "((revolve,twelfthnight),1)\n",
      "((er,merrywivesofwindsor),11)\n",
      "((renown,asyoulikeit),1)\n",
      "((cubiculo,twelfthnight),1)\n",
      "((All,twelfthnight),3)\n",
      "((power,loveslabourslost),8)\n",
      "((Albeit,asyoulikeit),1)\n",
      "((lips,tamingoftheshrew),3)\n",
      "((upshot,twelfthnight),1)\n",
      "((approach,midsummersnightsdream),4)\n",
      "((mean,muchadoaboutnothing),5)\n",
      "((embossed,asyoulikeit),1)\n",
      "((varnish,loveslabourslost),2)\n",
      "((Apollo,midsummersnightsdream),1)\n",
      "((spangled,midsummersnightsdream),1)\n",
      "((gentlemen,comedyoferrors),1)\n",
      "((Rebuke,loveslabourslost),1)\n"
     ]
    }
   ],
   "source": [
    "uniques.take(30).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.rdd.RDD[(String, (String, Int))] = MapPartitionsRDD[14] at map at <console>:30"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val words = uniques.map { word_file_count_tup3 => \n",
    "    (word_file_count_tup3._1._1, (word_file_count_tup3._1._2, word_file_count_tup3._2)) \n",
    "}\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.rdd.RDD[(String, Iterable[(String, Int)])] = ShuffledRDD[18] at sortByKey at <console>:32"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val wordGroups = words.groupByKey.sortByKey(ascending = true)\n",
    "wordGroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Long = 11951"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordGroups.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(,CompactBuffer((tamingoftheshrew,1), (asyoulikeit,1), (merrywivesofwindsor,1), (comedyoferrors,1), (midsummersnightsdream,1), (twelfthnight,1), (loveslabourslost,1), (muchadoaboutnothing,1)))\n",
      "(A,CompactBuffer((loveslabourslost,78), (midsummersnightsdream,39), (muchadoaboutnothing,31), (merrywivesofwindsor,38), (comedyoferrors,42), (asyoulikeit,34), (twelfthnight,47), (tamingoftheshrew,59)))\n",
      "(ABOUT,CompactBuffer((muchadoaboutnothing,18)))\n",
      "(ACT,CompactBuffer((asyoulikeit,22), (comedyoferrors,11), (tamingoftheshrew,12), (loveslabourslost,9), (muchadoaboutnothing,17), (twelfthnight,18), (merrywivesofwindsor,23), (midsummersnightsdream,9)))\n",
      "(ADAM,CompactBuffer((asyoulikeit,16)))\n",
      "(ADO,CompactBuffer((muchadoaboutnothing,18)))\n",
      "(ADRIANA,CompactBuffer((comedyoferrors,85)))\n",
      "(ADRIANO,CompactBuffer((loveslabourslost,111)))\n",
      "(AEGEON,CompactBuffer((comedyoferrors,20)))\n",
      "(AEMELIA,CompactBuffer((comedyoferrors,16)))\n",
      "(AEMILIA,CompactBuffer((comedyoferrors,3)))\n",
      "(AEacides,CompactBuffer((tamingoftheshrew,1)))\n",
      "(AEgeon,CompactBuffer((comedyoferrors,7)))\n",
      "(AEgle,CompactBuffer((midsummersnightsdream,1)))\n",
      "(AEmilia,CompactBuffer((comedyoferrors,4)))\n",
      "(AEsculapius,CompactBuffer((merrywivesofwindsor,1)))\n",
      "(AGUECHEEK,CompactBuffer((twelfthnight,2)))\n",
      "(ALL,CompactBuffer((midsummersnightsdream,2), (tamingoftheshrew,2)))\n",
      "(AMIENS,CompactBuffer((asyoulikeit,16)))\n",
      "(ANDREW,CompactBuffer((twelfthnight,104)))\n",
      "(ANGELO,CompactBuffer((comedyoferrors,36)))\n",
      "(ANN,CompactBuffer((merrywivesofwindsor,1)))\n",
      "(ANNE,CompactBuffer((merrywivesofwindsor,27)))\n",
      "(ANTIPHOLUS,CompactBuffer((comedyoferrors,195)))\n",
      "(ANTONIO,CompactBuffer((muchadoaboutnothing,32), (twelfthnight,32)))\n",
      "(ARMADO,CompactBuffer((loveslabourslost,111)))\n",
      "(AS,CompactBuffer((asyoulikeit,24)))\n",
      "(AUDREY,CompactBuffer((asyoulikeit,18)))\n",
      "(Abate,CompactBuffer((midsummersnightsdream,1), (loveslabourslost,1)))\n",
      "(Abbess,CompactBuffer((comedyoferrors,2)))\n"
     ]
    }
   ],
   "source": [
    "wordGroups.take(30).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[19] at mapValues at <console>:34"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val iiFirstPass2 = wordGroups.mapValues { iterable => \n",
    "    val vect = iterable.toVector.sortBy { file_count_tup2 => \n",
    "        (-file_count_tup2._2, file_count_tup2._1)\n",
    "    }\n",
    "    vect.mkString(\",\")\n",
    "}\n",
    "iiFirstPass2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Long = 11951"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iiFirstPass2.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(,(asyoulikeit,1),(comedyoferrors,1),(loveslabourslost,1),(merrywivesofwindsor,1),(midsummersnightsdream,1),(muchadoaboutnothing,1),(tamingoftheshrew,1),(twelfthnight,1))\n",
      "(A,(loveslabourslost,78),(tamingoftheshrew,59),(twelfthnight,47),(comedyoferrors,42),(midsummersnightsdream,39),(merrywivesofwindsor,38),(asyoulikeit,34),(muchadoaboutnothing,31))\n",
      "(ABOUT,(muchadoaboutnothing,18))\n",
      "(ACT,(merrywivesofwindsor,23),(asyoulikeit,22),(twelfthnight,18),(muchadoaboutnothing,17),(tamingoftheshrew,12),(comedyoferrors,11),(loveslabourslost,9),(midsummersnightsdream,9))\n",
      "(ADAM,(asyoulikeit,16))\n",
      "(ADO,(muchadoaboutnothing,18))\n",
      "(ADRIANA,(comedyoferrors,85))\n",
      "(ADRIANO,(loveslabourslost,111))\n",
      "(AEGEON,(comedyoferrors,20))\n",
      "(AEMELIA,(comedyoferrors,16))\n",
      "(AEMILIA,(comedyoferrors,3))\n",
      "(AEacides,(tamingoftheshrew,1))\n",
      "(AEgeon,(comedyoferrors,7))\n",
      "(AEgle,(midsummersnightsdream,1))\n",
      "(AEmilia,(comedyoferrors,4))\n",
      "(AEsculapius,(merrywivesofwindsor,1))\n",
      "(AGUECHEEK,(twelfthnight,2))\n",
      "(ALL,(midsummersnightsdream,2),(tamingoftheshrew,2))\n",
      "(AMIENS,(asyoulikeit,16))\n",
      "(ANDREW,(twelfthnight,104))\n",
      "(ANGELO,(comedyoferrors,36))\n",
      "(ANN,(merrywivesofwindsor,1))\n",
      "(ANNE,(merrywivesofwindsor,27))\n",
      "(ANTIPHOLUS,(comedyoferrors,195))\n",
      "(ANTONIO,(muchadoaboutnothing,32),(twelfthnight,32))\n",
      "(ARMADO,(loveslabourslost,111))\n",
      "(AS,(asyoulikeit,24))\n",
      "(AUDREY,(asyoulikeit,18))\n",
      "(Abate,(loveslabourslost,1),(midsummersnightsdream,1))\n",
      "(Abbess,(comedyoferrors,2))\n"
     ]
    }
   ],
   "source": [
    "iiFirstPass2.take(30).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Add a filter statement to remove the first entry for the blank word \"\"\n",
    "// Convert all words to lower case\n",
    "val iiFirstPass1 = sc.wholeTextFiles(shakespeare.toString).\n",
    "    flatMap { location_contents_tuple2 => \n",
    "        val words = location_contents_tuple2._2.split(\"\"\"\\W+\"\"\")\n",
    "        val fileName = location_contents_tuple2._1.split(pathSeparator).last\n",
    "        words.map(word => ((word.toLowerCase, fileName), 1)).\n",
    "            filter(word_file_one_tup3 => word_file_one_tup3._1._1.size > 0)\n",
    "    }.\n",
    "    reduceByKey((count1, count2) => count1 + count2).\n",
    "    map { word_file_count_tup3 => \n",
    "        (word_file_count_tup3._1._1, (word_file_count_tup3._1._2, word_file_count_tup3._2)) \n",
    "    }.\n",
    "    groupByKey.\n",
    "    sortByKey(ascending = true).\n",
    "    mapValues { iterable => \n",
    "        val vect = iterable.toVector.sortBy { file_count_tup2 => \n",
    "            (-file_count_tup2._2, file_count_tup2._1)\n",
    "        }\n",
    "        vect.mkString(\",\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a,(loveslabourslost,507),(merrywivesofwindsor,494),(muchadoaboutnothing,492),(asyoulikeit,461),(tamingoftheshrew,445),(twelfthnight,416),(midsummersnightsdream,281),(comedyoferrors,254))\n",
      "(abandon,(asyoulikeit,4),(tamingoftheshrew,1),(twelfthnight,1))\n",
      "(abate,(loveslabourslost,1),(midsummersnightsdream,1),(tamingoftheshrew,1))\n",
      "(abatement,(twelfthnight,1))\n",
      "(abbess,(comedyoferrors,8))\n",
      "(abbey,(comedyoferrors,9))\n",
      "(abbominable,(loveslabourslost,1))\n",
      "(abbreviated,(loveslabourslost,1))\n",
      "(abed,(asyoulikeit,1),(twelfthnight,1))\n",
      "(abetting,(comedyoferrors,1))\n",
      "(abhominable,(loveslabourslost,1))\n",
      "(abhor,(asyoulikeit,1),(comedyoferrors,1),(loveslabourslost,1),(merrywivesofwindsor,1),(muchadoaboutnothing,1))\n",
      "(abhors,(twelfthnight,2))\n",
      "(abide,(merrywivesofwindsor,3),(midsummersnightsdream,2))\n",
      "(abides,(muchadoaboutnothing,1))\n",
      "(ability,(muchadoaboutnothing,1),(twelfthnight,1))\n",
      "(abject,(comedyoferrors,1),(tamingoftheshrew,1))\n",
      "(abjure,(midsummersnightsdream,1))\n",
      "(abjured,(tamingoftheshrew,1),(twelfthnight,1))\n",
      "(able,(merrywivesofwindsor,4),(midsummersnightsdream,2),(asyoulikeit,1),(comedyoferrors,1),(tamingoftheshrew,1))\n",
      "(aboard,(comedyoferrors,5),(tamingoftheshrew,1))\n",
      "(abode,(tamingoftheshrew,1))\n",
      "(abominable,(asyoulikeit,1),(merrywivesofwindsor,1))\n",
      "(abortive,(loveslabourslost,1))\n",
      "(abound,(midsummersnightsdream,1))\n",
      "(about,(muchadoaboutnothing,35),(merrywivesofwindsor,27),(twelfthnight,10),(tamingoftheshrew,9),(asyoulikeit,7),(comedyoferrors,7),(midsummersnightsdream,7),(loveslabourslost,6))\n",
      "(above,(merrywivesofwindsor,6),(twelfthnight,6),(tamingoftheshrew,4),(loveslabourslost,3),(asyoulikeit,1),(comedyoferrors,1),(muchadoaboutnothing,1))\n",
      "(abraham,(merrywivesofwindsor,2))\n",
      "(abridgement,(midsummersnightsdream,1))\n",
      "(abroad,(loveslabourslost,2),(tamingoftheshrew,1))\n"
     ]
    }
   ],
   "source": [
    "iiFirstPass1.take(30).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Long = 10409"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iiFirstPass1.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val ii1 = sc.wholeTextFiles(shakespeare.toString).\n",
    "    flatMap {\n",
    "        case (location, contents) => \n",
    "            val words = contents.split(\"\"\"\\W+\"\"\").\n",
    "                filter(word => word.size > 0)                      // #1\n",
    "            val fileName = location.split(pathSeparator).last\n",
    "            words.map(word => ((word.toLowerCase, fileName), 1))   // #2\n",
    "    }.\n",
    "    reduceByKey((count1, count2) => count1 + count2).\n",
    "    map { \n",
    "        case ((word, fileName), count) => (word, (fileName, count)) \n",
    "    }.\n",
    "    groupByKey.\n",
    "    sortByKey(ascending = true).\n",
    "    mapValues { iterable => \n",
    "        val vect = iterable.toVector.sortBy { \n",
    "            case (fileName, count) => (-count, fileName) \n",
    "        }\n",
    "        vect.mkString(\",\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use Spark's DataFrame API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SQLContext\n",
    "val sqlContext = new SQLContext(sc)\n",
    "val ii1DF = sqlContext.createDataFrame(ii1).toDF(\"word\", \"locations_counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.DataFrame = [word: string, locations_counts: string]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii1DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|       word|    locations_counts|\n",
      "+-----------+--------------------+\n",
      "|          a|(loveslabourslost...|\n",
      "|    abandon|(asyoulikeit,4),(...|\n",
      "|      abate|(loveslabourslost...|\n",
      "|  abatement|    (twelfthnight,1)|\n",
      "|     abbess|  (comedyoferrors,8)|\n",
      "|      abbey|  (comedyoferrors,9)|\n",
      "|abbominable|(loveslabourslost,1)|\n",
      "|abbreviated|(loveslabourslost,1)|\n",
      "|       abed|(asyoulikeit,1),(...|\n",
      "|   abetting|  (comedyoferrors,1)|\n",
      "|abhominable|(loveslabourslost,1)|\n",
      "|      abhor|(asyoulikeit,1),(...|\n",
      "|     abhors|    (twelfthnight,2)|\n",
      "|      abide|(merrywivesofwind...|\n",
      "|     abides|(muchadoaboutnoth...|\n",
      "|    ability|(muchadoaboutnoth...|\n",
      "|     abject|(comedyoferrors,1...|\n",
      "|     abjure|(midsummersnights...|\n",
      "|    abjured|(tamingoftheshrew...|\n",
      "|       able|(merrywivesofwind...|\n",
      "+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ii1DF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supporting SQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Instead of creating a string for the list of (location,count) pairs, \n",
    "// which is opaque to our SQL schema (i.e., just a string), let's \"unzip\" the collection into two arrays, \n",
    "// one for the locations and one for the counts.\n",
    "val ii = sc.wholeTextFiles(shakespeare.toString).\n",
    "    flatMap {\n",
    "        case (location, contents) => \n",
    "            val words = contents.split(\"\"\"\\W+\"\"\").\n",
    "                filter(word => word.size > 0)                      // #1\n",
    "            val fileName = location.split(pathSeparator).last\n",
    "            words.map(word => ((word.toLowerCase, fileName), 1))   // #2\n",
    "    }.\n",
    "    reduceByKey((count1, count2) => count1 + count2).\n",
    "    map { \n",
    "        case ((word, fileName), count) => (word, (fileName, count)) \n",
    "    }.\n",
    "    groupByKey.\n",
    "    sortByKey(ascending = true).\n",
    "    map {                         // Must use map now, because we'll format new records. \n",
    "      case (word, iterable) =>    // Hence, pattern match on the whole input record.\n",
    "\n",
    "        val vect = iterable.toVector.sortBy { \n",
    "            case (fileName, count) => (-count, fileName) \n",
    "        }\n",
    "\n",
    "        // Use `Vector.unzip`, which returns a single, two element tuple, where each\n",
    "        // element is a collection, one for the locations and one for the counts. \n",
    "        // I use pattern matching to extract these two collections into variables.\n",
    "        val (locations, counts) = vect.unzip  \n",
    "\n",
    "        // Lastly, I'll compute the total count across all locations and return \n",
    "        // a new record with all four fields. The `reduceLeft` method takes a function\n",
    "        // that knows how to \"reduce\" the collection down to a final value, working \n",
    "        // from the left.\n",
    "        val totalCount = counts.reduceLeft((n1,n2) => n1+n2)\n",
    "\n",
    "        (word, totalCount, locations, counts)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a,3350,Vector(loveslabourslost, merrywivesofwindsor, muchadoaboutnothing, asyoulikeit, tamingoftheshrew, twelfthnight, midsummersnightsdream, comedyoferrors),Vector(507, 494, 492, 461, 445, 416, 281, 254))\n",
      "(abandon,6,Vector(asyoulikeit, tamingoftheshrew, twelfthnight),Vector(4, 1, 1))\n",
      "(abate,3,Vector(loveslabourslost, midsummersnightsdream, tamingoftheshrew),Vector(1, 1, 1))\n",
      "(abatement,1,Vector(twelfthnight),Vector(1))\n",
      "(abbess,8,Vector(comedyoferrors),Vector(8))\n",
      "(abbey,9,Vector(comedyoferrors),Vector(9))\n",
      "(abbominable,1,Vector(loveslabourslost),Vector(1))\n",
      "(abbreviated,1,Vector(loveslabourslost),Vector(1))\n",
      "(abed,2,Vector(asyoulikeit, twelfthnight),Vector(1, 1))\n",
      "(abetting,1,Vector(comedyoferrors),Vector(1))\n",
      "(abhominable,1,Vector(loveslabourslost),Vector(1))\n",
      "(abhor,5,Vector(asyoulikeit, comedyoferrors, loveslabourslost, merrywivesofwindsor, muchadoaboutnothing),Vector(1, 1, 1, 1, 1))\n",
      "(abhors,2,Vector(twelfthnight),Vector(2))\n",
      "(abide,5,Vector(merrywivesofwindsor, midsummersnightsdream),Vector(3, 2))\n",
      "(abides,1,Vector(muchadoaboutnothing),Vector(1))\n",
      "(ability,2,Vector(muchadoaboutnothing, twelfthnight),Vector(1, 1))\n",
      "(abject,2,Vector(comedyoferrors, tamingoftheshrew),Vector(1, 1))\n",
      "(abjure,1,Vector(midsummersnightsdream),Vector(1))\n",
      "(abjured,2,Vector(tamingoftheshrew, twelfthnight),Vector(1, 1))\n",
      "(able,9,Vector(merrywivesofwindsor, midsummersnightsdream, asyoulikeit, comedyoferrors, tamingoftheshrew),Vector(4, 2, 1, 1, 1))\n",
      "(aboard,6,Vector(comedyoferrors, tamingoftheshrew),Vector(5, 1))\n",
      "(abode,1,Vector(tamingoftheshrew),Vector(1))\n",
      "(abominable,2,Vector(asyoulikeit, merrywivesofwindsor),Vector(1, 1))\n",
      "(abortive,1,Vector(loveslabourslost),Vector(1))\n",
      "(abound,1,Vector(midsummersnightsdream),Vector(1))\n",
      "(about,108,Vector(muchadoaboutnothing, merrywivesofwindsor, twelfthnight, tamingoftheshrew, asyoulikeit, comedyoferrors, midsummersnightsdream, loveslabourslost),Vector(35, 27, 10, 9, 7, 7, 7, 6))\n",
      "(above,22,Vector(merrywivesofwindsor, twelfthnight, tamingoftheshrew, loveslabourslost, asyoulikeit, comedyoferrors, muchadoaboutnothing),Vector(6, 6, 4, 3, 1, 1, 1))\n",
      "(abraham,2,Vector(merrywivesofwindsor),Vector(2))\n",
      "(abridgement,1,Vector(midsummersnightsdream),Vector(1))\n",
      "(abroad,3,Vector(loveslabourslost, tamingoftheshrew),Vector(2, 1))\n"
     ]
    }
   ],
   "source": [
    "ii.take(30).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val iiDF = sqlContext.createDataFrame(ii).toDF(\"word\", \"total_count\", \"locations\", \"counts\")\n",
    "iiDF.cache\n",
    "iiDF.registerTempTable(\"inverted_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- word: string (nullable = true)\n",
      " |-- total_count: integer (nullable = false)\n",
      " |-- locations: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- counts: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iiDF.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Either[org.apache.toree.magic.CellMagicOutput,org.apache.toree.magic.LineMagicOutput] = Left(Map(text/plain -> +-----------+-----------+----------------+---------+\n",
       "|       word|total_count|    top_location|top_count|\n",
       "+-----------+-----------+----------------+---------+\n",
       "|          a|       3350|loveslabourslost|      507|\n",
       "|    abandon|          6|     asyoulikeit|        4|\n",
       "|      abate|          3|loveslabourslost|        1|\n",
       "|  abatement|          1|    twelfthnight|        1|\n",
       "|     abbess|          8|  comedyoferrors|        8|\n",
       "|      abbey|          9|  comedyoferrors|        9|\n",
       "|abbominable|          1|loveslabourslost|        1|\n",
       "|abbreviated|          1|loveslabourslost|        1|\n",
       "|       abed|          2|     asyoulikeit|        1|\n",
       "|   abetting|          1|  comedyoferrors|..."
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%SQL\n",
    "SELECT word, total_count, locations[0] AS top_location, counts[0] AS top_count \n",
    "FROM inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "val topLocations = sqlContext.sql(\"\"\"\n",
    "    SELECT word,  total_count, locations[0] AS top_1st_location, counts[0] AS top_1st_count, \n",
    "    locations[1] AS top_2nd_location, counts[1] AS top_2nd_count\n",
    "    FROM inverted_index \n",
    "    WHERE word LIKE 'love%' OR word LIKE 'unlove%' OR word LIKE 'hate%' \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+---------------------+-------------+---------------------+-------------+\n",
      "|word   |total_count|top_1st_location     |top_1st_count|top_2nd_location     |top_2nd_count|\n",
      "+-------+-----------+---------------------+-------------+---------------------+-------------+\n",
      "|hate   |22         |midsummersnightsdream|9            |asyoulikeit          |6            |\n",
      "|hated  |6          |midsummersnightsdream|4            |asyoulikeit          |2            |\n",
      "|hateful|5          |midsummersnightsdream|3            |loveslabourslost     |1            |\n",
      "|hates  |5          |asyoulikeit          |2            |merrywivesofwindsor  |1            |\n",
      "|hateth |1          |midsummersnightsdream|1            |null                 |null         |\n",
      "|love   |662        |loveslabourslost     |121          |asyoulikeit          |119          |\n",
      "|loved  |38         |asyoulikeit          |13           |muchadoaboutnothing  |13           |\n",
      "|lovely |15         |midsummersnightsdream|7            |tamingoftheshrew     |5            |\n",
      "|lover  |33         |asyoulikeit          |14           |midsummersnightsdream|10           |\n",
      "|lovers |31         |midsummersnightsdream|17           |asyoulikeit          |6            |\n",
      "|loves  |51         |muchadoaboutnothing  |10           |merrywivesofwindsor  |9            |\n",
      "|lovest |8          |tamingoftheshrew     |3            |muchadoaboutnothing  |2            |\n",
      "|loveth |2          |loveslabourslost     |1            |tamingoftheshrew     |1            |\n",
      "|unloved|1          |midsummersnightsdream|1            |null                 |null         |\n",
      "+-------+-----------+---------------------+-------------+---------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topLocations.show(numRows = 40, truncate = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.DataFrame = [word: string, total_count: int ... 2 more fields]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topLocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
